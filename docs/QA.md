# 常见问题

## 为什么训练框架不支持 batch size > 1？

## 为什么不删除某些模型中的冗余参数？

## 为什么 FP8 量化没有任何加速效果？

## 为什么训练框架不支持原生 FP8 精度训练？

即使硬件条件允许，我们目前也没有任何支持原生 FP8 精度训练的规划。目前原生 FP8 精度训练的主要挑战是梯度爆炸导致的精度溢出，为了保证训练的稳定性，需针对性地重新设计模型结构，然而目前还没有任何模型开发者愿意这么做。此外，使用原生 FP8 精度训练的模型，在推理时若没有 Hopper 架构 GPU，则只能以 BF16 精度进行计算，理论上其生成效果反而不如 FP8。因此，原生 FP8 精度训练技术是极不成熟的，我们静观开源社区的技术发展。
